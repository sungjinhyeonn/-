{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BewQSKXZVHjf"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "import torch\n",
        "\n",
        "# colab-GPU 사용 확인\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('GPU 연결 실패!')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# RAM 사용량 체크\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('{:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "# pytorch-GPU 연결 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('학습을 진행하는 기기:',device)\n",
        "\n",
        "# 구글 드라이브 연결. 만약 직접 데이터셋을 사용한다면 주석 해제.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai"
      ],
      "metadata": {
        "id": "dTmecSqNqg1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.data.external import untar_data, URLs\n",
        "import glob\n",
        "\n",
        "coco_path = untar_data(URLs.COCO_SAMPLE)"
      ],
      "metadata": {
        "id": "yghj6oiUq_95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(coco_path)"
      ],
      "metadata": {
        "id": "XLdmMOwWsgPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = glob.glob(str(coco_path) + \"/train_sample/*.jpg\")"
      ],
      "metadata": {
        "id": "vbAhp-LGrbWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "chosen_paths = np.random.choice(paths, 5000, replace=False)\n",
        "index = np.random.permutation(5000)\n",
        "\n",
        "train_paths = chosen_paths[index[:4000]] # 앞 4000장\n",
        "val_paths = chosen_paths[index[4000:]]  # 뒤 1000장\n",
        "print(len(train_paths), len(val_paths))"
      ],
      "metadata": {
        "id": "htgJ2L8XswBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = matplotlib.image.imread(train_paths[0])\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GEaKuAYMtvkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "import numpy as np\n",
        "\n",
        "class ColorizationDataset(Dataset):\n",
        "  # 생성자를 만들어 봅시다!\n",
        "  def __init__(self, paths, mode='train'):\n",
        "    self.mode = mode\n",
        "    self.paths = paths\n",
        "\n",
        "    if mode == 'train':\n",
        "      self.transforms = transforms.Compose([\n",
        "          transforms.Resize((256, 256), Image.BICUBIC),\n",
        "          transforms.RandomHorizontalFlip()\n",
        "      ])\n",
        "    elif mode == \"val\":    \n",
        "      self.transforms = transforms.Resize((256, 256), Image.BICUBIC)\n",
        "    else:\n",
        "      raise Exception(\"Train or validation only!\")\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.paths[index]).convert(\"RGB\")\n",
        "    img = np.array(self.transforms(img))\n",
        "    img = rgb2lab(img).astype(\"float32\")\n",
        "    img = transforms.ToTensor()(img)\n",
        "    L = img[[0], ...] / 50. - 1 # ~1부터 1 사이로 정규화를 하는 겁니다!\n",
        "    ab = img[[1, 2], ...] / 110.\n",
        "\n",
        "    return {'L': L, 'ab': ab}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)"
      ],
      "metadata": {
        "id": "cbR1FpK2w1Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = ColorizationDataset(train_paths, mode='train')\n",
        "dataset_val = ColorizationDataset(val_paths, mode='val')\n",
        "\n",
        "\n",
        "# [배치 사이즈, 채널, height, width]\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=16, num_workers=2, pin_memory=True)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=16, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "d6T_uIAjsLo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "### pix2pix 생성자 선언\n",
        "class pix2pix_Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    )\n",
        "\n",
        "    self.encoder_1 = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(128)\n",
        "    )\n",
        "\n",
        "    self.encoder_2 = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(256)\n",
        "    )\n",
        "\n",
        "    self.encoder_3 = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(512)\n",
        "    )\n",
        "\n",
        "    self.encoder_4 = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(512)\n",
        "    )\n",
        "\n",
        "    self.encoder_5 = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(512)\n",
        "    )\n",
        "\n",
        "    self.encoder_6 = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "        nn.BatchNorm2d(512)\n",
        "    )\n",
        "\n",
        "    self.middle = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512)\n",
        "    )\n",
        "\n",
        "    self.decoder_6 = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.Dropout(0.5)\n",
        "    )\n",
        "\n",
        "    self.decoder_5 = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.Dropout(0.5)\n",
        "    )\n",
        "\n",
        "    self.decoder_4 = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.Dropout(0.5)\n",
        "    )\n",
        "\n",
        "    self.decoder_3 = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(256)\n",
        "    )\n",
        "\n",
        "    self.decoder_2 = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(512, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(128)\n",
        "    )\n",
        "\n",
        "    self.decoder_1 = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "\n",
        "    self.output_layer = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    input_layer = self.input_layer(x)\n",
        "\n",
        "    encoder_1 = self.encoder_1(input_layer)\n",
        "    encoder_2 = self.encoder_2(encoder_1)\n",
        "    encoder_3 = self.encoder_3(encoder_2)\n",
        "    encoder_4 = self.encoder_4(encoder_3)\n",
        "    encoder_5 = self.encoder_5(encoder_4)\n",
        "    encoder_6 = self.encoder_6(encoder_5)\n",
        "\n",
        "    middle = self.middle(encoder_6)\n",
        "\n",
        "    cat_6 = torch.cat((middle, encoder_6), dim=1)\n",
        "    decoder_6 = self.decoder_6(cat_6)\n",
        "    cat_5 = torch.cat((decoder_6, encoder_5), dim=1)\n",
        "    decoder_5 = self.decoder_5(cat_5)\n",
        "    cat_4 = torch.cat((decoder_5, encoder_4), dim=1)\n",
        "    decoder_4 = self.decoder_4(cat_4)\n",
        "    cat_3 = torch.cat((decoder_4, encoder_3), dim=1)\n",
        "    decoder_3 = self.decoder_3(cat_3)\n",
        "    cat_2 = torch.cat((decoder_3, encoder_2), dim=1)\n",
        "    decoder_2 = self.decoder_2(cat_2)\n",
        "    cat_1 = torch.cat((decoder_2, encoder_1), dim=1)\n",
        "    decoder_1 = self.decoder_1(cat_1)\n",
        "\n",
        "    x = self.output_layer(decoder_1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "E6mSmUC0vBOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pix2pix_Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        \n",
        "        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        \n",
        "        nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        \n",
        "        nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, bias=False)\n",
        "\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n"
      ],
      "metadata": {
        "id": "YgfjpRnDsPVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "  if type(m) == nn.Conv2d:\n",
        "    nn.init.normal_(m.weight.data, mean=0.0, std=0.02)\n",
        "    print(\"nn.Conv2d initialized\")\n",
        "  elif type(m) == nn.ConvTranspose2d:\n",
        "    nn.init.normal_(m.weight.data, mean=0.0, std=0.02)\n",
        "    print(\"nn.ConvTransposed2d initialized\")\n",
        "  elif type(m) == nn.BatchNorm2d:\n",
        "    nn.init.normal_(m.weight.data, mean=1., std=0.02)\n",
        "    nn.init.constant_(m.bias.data, 0.)\n",
        "    print(\"nn.BatchNorm2d initialized\")\n",
        "\n",
        "def initialize_model(model):\n",
        "  model.apply(init_weights)\n",
        "  return model"
      ],
      "metadata": {
        "id": "8hbTqvFu7xSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(1.0))\n",
        "        self.register_buffer('fake_label', torch.tensor(0.0))\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "    \n",
        "    def __call__(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "qW2-a3Xd8p2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lab를 rgb로 만드는 함수를 만들어 봅시다!\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    # Lab 컬러 채널을 만들어 봅시다! permute가 사용된 이유는 [배치 사이즈, 채널, 256, 256]를 [배치 사이즈, 256, 256, 채널]로 만들기 위해서\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)"
      ],
      "metadata": {
        "id": "xjaLUsyM8puv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# generator를 초기화\n",
        "model_generator = initialize_model(pix2pix_Generator())\n",
        "# generator를 gpu로 보내기\n",
        "model_generator.to(device)\n",
        "\n",
        "# discriminator를 초기화\n",
        "model_discriminator = initialize_model(pix2pix_Discriminator())\n",
        "# discriminator를 gpu로 보내기\n",
        "model_discriminator.to(device)\n",
        "\n",
        "# 로스 함수 선언하기\n",
        "criterion = GANLoss().to(device)\n",
        "# L1 로스 함수 선언하기\n",
        "L1 = nn.L1Loss()\n",
        "\n",
        "# generator의 optimizer 선언하기\n",
        "optimizer_generator = optim.Adam(model_generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "# discriminator의 optimizer 선언하기\n",
        "optimizer_discriminator = optim.Adam(model_discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "# epoch 선언하기\n",
        "epochs = 100\n",
        "\n",
        "# 실제 훈련 시작! 에포크가 돕니다! -> 전체 트레이닝 셋이 한번씩 도는 것이 에포크!\n",
        "for e in range(epochs):\n",
        "    # tqdm 선언 -> for loop을 보여주기 위해 사용\n",
        "    for index, data in enumerate(tqdm(dataloader_train)):\n",
        "        \n",
        "        # L 데이터를 gpu로 보냅시다!\n",
        "        L = data['L'].to(device)\n",
        "        # ab 데이터를 gpu로 보냅시다!\n",
        "        ab = data['ab'].to(device)\n",
        "\n",
        "        # generator에 L을 넣고, 나온 아웃풋 fake color를 얻어봅시다.  \n",
        "        fake_color = model_generator(L)\n",
        "        # discriminator를 훈련시킵시다!\n",
        "        model_discriminator.train()\n",
        "        # discriminator를 훈련시키기 위해서 discriminator의 모든 파라미터에 대한 기울기를 저장하자! -> 백프롭을 하자!\n",
        "        for parameter in model_discriminator.parameters():\n",
        "            parameter.requires_grad = True\n",
        "        # zero_grad -> pytorch에서는 interation이 끝나면 gradient를 항상 0으로 만들어 주어야 함. 이전 iteration의 기울기 값이 영향을 미칠 수 있기 때문.\n",
        "        optimizer_discriminator.zero_grad()\n",
        "\n",
        "        # L과 ab 채널을 합쳐서 가짜 이미지를 만들어줍시다!\n",
        "        fake_image = torch.cat([L, fake_color], dim=1)\n",
        "        # discriminator에 가짜 이미지를 넣어봅시다. 다만, 여기서 가짜 이미지는 건들이면 안되니, detach()를 사용하여 텐서를 복사합시다!\n",
        "        fake_preds = model_discriminator(fake_image.detach())\n",
        "        # discriminator의 로스를 재 봅시다!\n",
        "        loss_discriminator_fake = criterion(fake_preds, False)\n",
        "        # 그렇담 이번엔 진짜 이미지를 만들어 봅시다!\n",
        "        real_image = torch.cat([L, ab], dim=1)\n",
        "        # discriminator에 진짜 이미지를 넣어봅시다.\n",
        "        real_preds = model_discriminator(real_image)\n",
        "        # discriminator의 로스를 재 봅시다!\n",
        "        loss_discriminator_real = criterion(real_preds, True)\n",
        "        # discriminator의 전체 로스를 선언합시다! 두 로스를 더했으니 반으로 줄입시다!\n",
        "        loss_discriminator_total = (loss_discriminator_fake + loss_discriminator_real) * 0.5\n",
        "        # discriminator를 역전파시킵니다!\n",
        "        loss_discriminator_total.backward()\n",
        "        # 역전파 단계에서 수집된 변화도로 파라미터를 조정합시다!!!!!!\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "        \n",
        "        # 자 이제 generator를 학습시켜봅시다!!!!\n",
        "        model_generator.train()\n",
        "        # generator를 학습해야 하니, discriminator를 잠시 freeze시킵니다!\n",
        "        for parameter in model_discriminator.parameters():\n",
        "            parameter.requires_grad = False\n",
        "        # generator 학습에 앞서서, zero_grad()를 통해 기울기를 0으로 초기화해줍시다!\n",
        "        optimizer_generator.zero_grad()\n",
        "\n",
        "        # 가짜 이미지를 만들어봅시다!!!\n",
        "        fake_image = torch.cat([L, fake_color], dim=1)\n",
        "        # Generator가 생성한 가짜 이미지를 앞서 훈련된 discriminator에 넣어 봅시다!!!\n",
        "        fake_preds = model_discriminator(fake_image)\n",
        "        # Generator가 생성한 이미지를 discriminator가 어떻게 판단했는지를 확인하기 위해 loss를 계산합시다!\n",
        "        loss_generator_GAN = criterion(fake_preds, True)\n",
        "        # Generator에 생성한 컬러정보가 원본이랑 얼마나 다른지 L1 로스를 통해 알아봅시다! 100은 람다!\n",
        "        loss_generator_L1 = L1(fake_color, ab) * 100.\n",
        "        # Generator의 이미지에 대한 discriminator loss와, Generator가 생성한 ab 채널의 로스를 더해줍니다!\n",
        "        loss_generator_total = loss_generator_GAN + loss_generator_L1\n",
        "        # Generator를 역전파시킵니다!\n",
        "        loss_generator_total.backward()\n",
        "        # 역전파 단계에서 수집된 변화도로 generator를 변화시킵시다!!!\n",
        "        optimizer_generator.step()\n",
        "\n",
        "        # 200번재 인덱스마다\n",
        "        if index % 200 == 0:\n",
        "            # 에포크를 프린트\n",
        "            print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "            # 몇번째 iteration인지 출력\n",
        "            print(f\"Iteration {index}/{len(dataloader_train)}\")\n",
        "            # 자잘한 오류 메세지를 없애기 위해\n",
        "            with warnings.catch_warnings():\n",
        "                # 자잘한 오류 메세지를 없애기 위해\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                # generator가 훈련되면 안되니! eval mode로 변환!\n",
        "                model_generator.eval()\n",
        "                # generator 기울기 업데이트 막아버리자!\n",
        "                with torch.no_grad():\n",
        "                    # L채널을 gpu로 보낸다\n",
        "                    L = data['L'].to(device)\n",
        "                    # ab채널을 gpu로 보낸다\n",
        "                    ab = data['ab'].to(device)\n",
        "                    # generator에 넣어서 가짜 색을 입힌다.\n",
        "                    fake_color = model_generator(L)\n",
        "                # 다시 generator를 훈련 모드로 변환!\n",
        "                model_generator.train()\n",
        "                # 가짜 색 복사\n",
        "                fake_color = fake_color.detach()\n",
        "                # 진짜 색\n",
        "                real_color = ab\n",
        "\n",
        "                # 가짜 이미지를 생성하자\n",
        "                fake_imgs = lab_to_rgb(L, fake_color)\n",
        "                # 진짜 이미지를 생성하자\n",
        "                real_imgs = lab_to_rgb(L, real_color)\n",
        "                \n",
        "                fig = plt.figure(figsize=(10, 8))\n",
        "                ax = plt.subplot(3, 3, 1)\n",
        "                ax.imshow(L[1][0].cpu(), cmap='gray')\n",
        "                ax.axis(\"off\")\n",
        "                ax = plt.subplot(3, 3, 2)\n",
        "                ax.imshow(fake_imgs[1])\n",
        "                ax.axis(\"off\")\n",
        "                ax = plt.subplot(3, 3, 3)\n",
        "                ax.imshow(real_imgs[1])\n",
        "                ax.axis(\"off\")\n",
        "                plt.show()"
      ],
      "metadata": {
        "id": "8tMHy_HRAwym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cnquip6o64CT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}